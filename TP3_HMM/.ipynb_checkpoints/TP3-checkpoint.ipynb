{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SD-TSIA214 Machine Learning For Text Mining\n",
    "# Text segmentation using Hidden Markov Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task : automatic segmentation of mails\n",
    "This Lab aims to build an email segmentation tool, dedicated to separate the email header from its body. It is proposed to perform this task by learning a HMM with two states, one (state 1) for the header, the other (state 2) for the body. In this model, it is assumed that each mail actually contains a header : the decoding necessarily begins in the state 1.\n",
    "\n",
    "## 1. Give the value of the π vector of the initial probabilities\n",
    "It is said above that our HMM has necessarily an initial state of 1. So, the π vector of the initial probabilities will have the following form:\n",
    "\n",
    "$$π^{T} = (1, 0)$$\n",
    "\n",
    "Since the HMM will be in state 0 with probability 0 and in state 1 with probability 1, i.e. always.\n",
    "\n",
    "Knowing that each mail contains exactly one header and one body, each mail follows once the transition from 1 to 2. The transition matrix (A(i, j) = P(j|i)) estimated on a labeled small corpus has thus the following form :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99218078e-01, 7.81921964e-04],\n",
       "       [0.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[0.999218078035812, 0.000781921964187974], [0, 1]])\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What is the probability to move from state 1 to state 2 ? What is the probability to remain in state 2 ? What is the lower/higher probability ? Try to explain why \n",
    "\n",
    "Probabilities of movements between states can be found in the transition matrix A, which was just given. The i index (row index) determines the starting state, while the j index (column index) determines the arriving state. Thus:\n",
    "\n",
    "- Probability to move from state 1 to state 2: A(1,2) = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000781921964187974"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Probability to remain in state 2: A(2,2) = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability to remain in state 2 is actually the highest obtainable probability (=1), and this makes sense in our use case: once our email is in the state corresponding to the body, we can't go back anymore to the header state with more iterations, that correspond to reading more characters. In fact, an email's body goes from its beginning to end of an email, and in no case is followed by another header. As a consequence, when the number of iterations/observation n goes to infinity, our observed Markov Chain will forcely be in state 1, meaning that - as stated before - the email will necessarily have both a header and a body.\n",
    "\n",
    "On the contrary, the probability of moving from state 1 to state 2 is much lower because in average we have to read a significant number of characters - and, therefore, wait for several iterations - before being able to affirm that the email has also a body.\n",
    "\n",
    "For example, if we had built our model along with the transition matrix A using some strange kind of emails that have 3 characters in the header and (in average) more than 2000 in the body, this probability would be much higher. Obviously, the creation of the HMM and thus our probabilty also depend on the observations, which influence directly the hidden process and indirectly the observed one: if I had trained it with headers containing only 'a' characters and bodies that never contain the 'a' character, this would surely impact the transition probability matrix.\n",
    "\n",
    "A mail is represented by a sequence of characters. Let N be the number of different characters. Each part of the mail is characterized by a discrete probability distribution on the characters P(c|s), with s = 1 or s = 2.\n",
    "\n",
    "## 3. What is the size of the corresponding matrix ?\n",
    "The size of the corrispondig matrix is Nx|s|: since we are encoding characters as ASCII values, which range from 1 to 256, the matrix will have a size of 256x2, namely 256 rows and 2 columns.\n",
    "\n",
    "## Material\n",
    "### Coding/decoding mails\n",
    "\n",
    "Emails are represented as ASCII character vectors.\n",
    "In dat.zip, mail.txt in a vector of numbers (one vector per line). that can be transformed into a vector of numbers (between 0 and 255) in a text;\n",
    "Files of the form dat /*. dat contain the already encoded versions of the corresponding mails. The list is in mail.lst.\n",
    "\n",
    "### Visualizing segmentation\n",
    "Finally, the utility segment.pl allows to visualize a segmentation produced by your segmenter in the form of the best path found by the Viterbi algorithm (in a vector of 1 and 2). It produces a file where the segmentation is visualized. \n",
    "\n",
    "To use it :\n",
    "\n",
    "perl segment.pl mail.txt path.dat\n",
    "\n",
    "### Distribution files\n",
    "For the first part of the Lab, we work with the distributions that are provided in the P.dat file. \n",
    "\n",
    "Each of the columns of this file contains the distribution of the probabilities of occurrence of each character of the ASCII codes respectively in the header and in the body. These distributions were learned on a small corpus labeled with 10 emails ; there are obvious differences, especially in areas where ASCII codes correspond to alphabetic characters, as you can see by viewing these distributions.\n",
    "\n",
    "#### To implement:\n",
    "\n",
    "All the work is to be done under Python.\n",
    "\n",
    "- implement the Viterbi algorithm. Concretely, it comes to coding a function which takes as argument a vector of observations and the parameters of the model, and returns a vector of states representing the most probable sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Viterbi Algorithm Implementation\n",
    "    \n",
    "    Inputs:\n",
    "        - obs: a 1-d nparray containing the observations. Its values must be lesser \n",
    "            or equal than the number of rows of the conditional probability matrix. \n",
    "        - states: a 1-d nparray containing the number of possible states. Its size\n",
    "            has to be equal to the number of columns of the conditional probability matrix.\n",
    "        - trans: a 2-d nparray transition probability matrix containing the transition \n",
    "            probabilities for the observed process.\n",
    "        - start_prob: a 1-d nparray containing the starting probabilities for the observed\n",
    "            process. Its length has to be equal to the number of possible states.\n",
    "        - cond_prob: also known as emission probability, it is a 2-d nparray having a number\n",
    "            of columns equal to the number of possible states.\n",
    "    \n",
    "    Returns:\n",
    "        - seq: a 1-d nparray containing, for each observation given in the input, the\n",
    "            corresponding state that represent the most probable sequence\n",
    "            \n",
    "\"\"\"\n",
    "\n",
    "def viterbiAlgorithm(obs, states, trans, start_prob, cond_prob):\n",
    "    # Rescaling function that avoids state probabilities going to zero\n",
    "    # Computes the order of magnitude of the last values in the array \n",
    "    # and rescales them back to 10^-1\n",
    "    def rescale(state_probs, last_row):\n",
    "        # Compute order of magnitude\n",
    "        om = int(np.log10(np.max(state_probs[last_row,:])))\n",
    "        # Rescale\n",
    "#         print('Before rescaling ' + str(state_probs[last_row, :]) + ' - OM ' + str(om) + ' Resc factor ' + str((om+1)))\n",
    "        state_probs[last_row, :] = state_probs[last_row, :]*(10**(-1*(om+1)))\n",
    "#         print('After rescaling ' + str(state_probs[last_row, :]))\n",
    "        return state_probs\n",
    "    \n",
    "    # State probabilities\n",
    "    state_probs = np.zeros((len(obs), len(states)))\n",
    "    # Sequence of states\n",
    "    path = {}\n",
    "    \n",
    "    for i in range(0,len(observations)):\n",
    "        \n",
    "        # First iteration\n",
    "        if i == 0:\n",
    "            # Initialize states probabilites \n",
    "            for state in range(0,len(states)):\n",
    "                state_probs[i][state] = start_prob[state] * cond_prob[obs[i]][state]\n",
    "                path[state] = [states[state]]\n",
    "#             print('States probabilities: ' + str(state_probs[i]))\n",
    "        else:\n",
    "            # Update\n",
    "            tempPath = {}\n",
    "            probs = np.zeros((len(states), len(states)))            \n",
    "            for arr_state in range(0, len(states)):\n",
    "                (probs, state) = max([(state_probs[i-1][dep_state] * trans[dep_state][arr_state] * cond_prob[obs[i]][arr_state], \n",
    "                                      dep_state) for dep_state in states])\n",
    "                state_probs[i, :] = probs\n",
    "                \n",
    "#                 for dep_state in range(0, len(states)):\n",
    "#                     probs[arr_state][dep_state] = state_probs[i-1][dep_state]*trans[dep_state][arr_state]*cond_prob[obs[i]][arr_state]\n",
    "                    # We didn't multiply by 0, then be careful not to put a 0 there\n",
    "                    # because that's not a zero\n",
    "#                     if (trans[dep_state][arr_state] != 0) & (state_probs[i-1][dep_state] != 0) :\n",
    "#                         probs[dep_state] += np.finfo(np.double).tiny\n",
    "#             state_probs[i] = np.max(probs, axis=1)\n",
    "            r,c = np.unravel_index(probs.argmax(), probs.shape)\n",
    "            state_probs[i] = probs[:,c]\n",
    "            seq.append(states[r])\n",
    "#             print('Observation ' + str(i) + ' - Last State ' + str(seq[-1]) + ' - Probabilities: ')\n",
    "#             print(str(probs))\n",
    "#             print('Max prob : ' + str(probs[r][c]) + ' - R, C : ' + str(r) + ', ' + str(c) + ' - State: ' + str(states[c]))\n",
    "#             print('States probabilities: ' + str(state_probs[i]))\n",
    "            state_probs = rescale(state_probs, i)\n",
    "    seq[-1] = states[np.argmax(state_probs[])\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 2)\n",
      "States probabilities: [0.00168136 0.        ]\n"
     ]
    }
   ],
   "source": [
    "distributions = np.loadtxt('P.text', dtype=float)\n",
    "print(distributions.shape)\n",
    "distributions\n",
    "\n",
    "observations = np.loadtxt('./dat/mail30.dat', dtype=int)\n",
    "# print(observations.shape)\n",
    "# print(str(observations.max())+' '+str(observations.min()))\n",
    "\n",
    "p = viterbiAlgorithm(obs=observations, states=[1,2], start_prob=[1,0], trans=A, cond_prob=distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test it on some mails that are given in the dat directory (especially mail11.txt to mail30.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MAIL 11 STATES : \n",
      "State 1 from observation 0 to 3223\n",
      "State 2 from observation 3224 to 3473\n",
      "--- MAIL 12 STATES : \n",
      "State 1 from observation 0 to 666\n",
      "State 2 from observation 667 to 3991\n",
      "--- MAIL 13 STATES : \n",
      "State 1 from observation 0 to 1379\n",
      "State 2 from observation 1380 to 3326\n",
      "--- MAIL 14 STATES : \n",
      "State 1 from observation 0 to 3093\n",
      "State 2 from observation 3094 to 6574\n",
      "--- MAIL 15 STATES : \n",
      "State 1 from observation 0 to 2209\n",
      "State 2 from observation 2210 to 6806\n",
      "--- MAIL 16 STATES : \n",
      "State 1 from observation 0 to 2484\n",
      "State 2 from observation 2485 to 2625\n",
      "--- MAIL 17 STATES : \n",
      "State 1 from observation 0 to 3058\n",
      "State 2 from observation 3059 to 3423\n",
      "--- MAIL 18 STATES : \n",
      "State 1 from observation 0 to 585\n",
      "State 2 from observation 586 to 3075\n",
      "--- MAIL 19 STATES : \n",
      "State 1 from observation 0 to 2253\n",
      "State 2 from observation 2254 to 2618\n",
      "--- MAIL 20 STATES : \n",
      "State 1 from observation 0 to 586\n",
      "State 2 from observation 587 to 2432\n",
      "--- MAIL 21 STATES : \n",
      "State 1 from observation 0 to 2297\n",
      "State 2 from observation 2298 to 2662\n",
      "--- MAIL 22 STATES : \n",
      "State 1 from observation 0 to 1403\n",
      "State 2 from observation 1404 to 3641\n",
      "--- MAIL 23 STATES : \n",
      "State 1 from observation 0 to 2102\n",
      "State 2 from observation 2103 to 3748\n",
      "--- MAIL 24 STATES : \n",
      "State 1 from observation 0 to 1716\n",
      "State 2 from observation 1717 to 3699\n",
      "--- MAIL 25 STATES : \n",
      "State 1 from observation 0 to 1444\n",
      "State 2 from observation 1445 to 3236\n",
      "--- MAIL 26 STATES : \n",
      "State 1 from observation 0 to 3678\n",
      "State 2 from observation 3679 to 4465\n",
      "--- MAIL 27 STATES : \n",
      "State 1 from observation 0 to 1934\n",
      "State 2 from observation 1935 to 3146\n",
      "--- MAIL 28 STATES : \n",
      "State 1 from observation 0 to 1292\n",
      "State 2 from observation 1293 to 2539\n",
      "--- MAIL 29 STATES : \n",
      "State 1 from observation 0 to 1411\n",
      "State 2 from observation 1412 to 2888\n",
      "--- MAIL 30 STATES : \n",
      "State 1 from observation 0 to 585\n",
      "State 2 from observation 586 to 5158\n"
     ]
    }
   ],
   "source": [
    "def printPath(path):\n",
    "    summary = []\n",
    "    summary.append({ 'start': 0, 'end': 0, 'value': path[0]})\n",
    "    for i in range(1, len(path)):\n",
    "        if path[i] != path[i-1]:\n",
    "            summary.append({ 'start': i, 'end': i, 'value': path[i] })\n",
    "        else:\n",
    "            summary[-1]['end'] = i\n",
    "    \n",
    "    for s in summary:\n",
    "        print('State ' + str(s['value']) + ' from observation ' + str(s['start']) + ' to ' + str(s['end']))\n",
    "        \n",
    "for i in range(11,31):\n",
    "    observations = np.loadtxt('./dat/mail'+str(i)+'.dat', dtype=int)\n",
    "    p = viterbiAlgorithm(obs=observations, states=[1,2], start_prob=[1,0], trans=A, cond_prob=distributions)\n",
    "    print('--- MAIL ' + str(i) + ' STATES : ')\n",
    "    printPath(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Print the track and present and discuss the results obtained on mail11.txt to mail30.txt\n",
    "\n",
    "Further questions\n",
    "\n",
    "## 5. How would you model the problem if you had to segment the mails in more than two parts (for example : header, body, signature) ?\n",
    "\n",
    "## 6. How would you model the problem of separating the portions of mail included, knowing that they always start with the character \">\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
